{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import contextlib\n",
    "import functools\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from six.moves import urllib\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import tensorflow.compat.v2 as tf\n",
    "tf.enable_v2_behavior()\n",
    "\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = os.path.join(os.sep, 'tmp', 'datasets')\n",
    "\n",
    "\n",
    "def make_val_and_grad_fn(value_fn):\n",
    "  @functools.wraps(value_fn)\n",
    "  def val_and_grad(x):\n",
    "    return tfp.math.value_and_gradient(value_fn, x)\n",
    "  return val_and_grad\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def timed_execution():\n",
    "  t0 = time.time()\n",
    "  yield\n",
    "  dt = time.time() - t0\n",
    "  print('Evaluation took: %f seconds' % dt)\n",
    "\n",
    "\n",
    "def np_value(tensor):\n",
    "  \"\"\"Get numpy value out of possibly nested tuple of tensors.\"\"\"\n",
    "  if isinstance(tensor, tuple):\n",
    "    return type(tensor)(*(np_value(t) for t in tensor))\n",
    "  else:\n",
    "    return tensor.numpy()\n",
    "\n",
    "def run(optimizer):\n",
    "  \"\"\"Run an optimizer and measure it's evaluation time.\"\"\"\n",
    "  optimizer()  # Warmup.\n",
    "  with timed_execution():\n",
    "    result = optimizer()\n",
    "  return np_value(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L-BFGS for simple quadratic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation took: 0.049066 seconds\n",
      "L-BFGS Results\n",
      "Converged: True\n",
      "Location of the minimum: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Number of iterations: 10\n"
     ]
    }
   ],
   "source": [
    "# Fix numpy seed for reproducibility\n",
    "np.random.seed(12345)\n",
    "\n",
    "# The objective must be supplied as a function that takes a single\n",
    "# (Tensor) argument and returns a tuple. The first component of the\n",
    "# tuple is the value of the objective at the supplied point and the\n",
    "# second value is the gradient at the supplied point. The value must\n",
    "# be a scalar and the gradient must have the same shape as the\n",
    "# supplied argument.\n",
    "\n",
    "# The `make_val_and_grad_fn` decorator helps transforming a function\n",
    "# returning the objective value into one that returns both the gradient\n",
    "# and the value. It also works for both eager and graph mode.\n",
    "\n",
    "dim = 10\n",
    "minimum = np.ones([dim])\n",
    "scales = np.exp(np.random.randn(dim))\n",
    "\n",
    "@make_val_and_grad_fn\n",
    "def quadratic(x):\n",
    "  return tf.reduce_sum(scales * (x - minimum) ** 2, axis=-1)\n",
    "\n",
    "# The minimization routine also requires you to supply an initial\n",
    "# starting point for the search. For this example we choose a random\n",
    "# starting point.\n",
    "start = np.random.randn(dim)\n",
    "\n",
    "# Finally an optional argument called tolerance let's you choose the\n",
    "# stopping point of the search. The tolerance specifies the maximum\n",
    "# (supremum) norm of the gradient vector at which the algorithm terminates.\n",
    "# If you don't have a specific need for higher or lower accuracy, leaving\n",
    "# this parameter unspecified (and hence using the default value of 1e-8)\n",
    "# should be good enough.\n",
    "tolerance = 1e-10\n",
    "\n",
    "@tf.function\n",
    "def quadratic_with_lbfgs():\n",
    "  return tfp.optimizer.lbfgs_minimize(\n",
    "    quadratic,\n",
    "    initial_position=tf.constant(start),\n",
    "    tolerance=tolerance)\n",
    "\n",
    "results = run(quadratic_with_lbfgs)\n",
    "\n",
    "# The optimization results contain multiple pieces of information. The most\n",
    "# important fields are: 'converged' and 'position'.\n",
    "# Converged is a boolean scalar tensor. As the name implies, it indicates\n",
    "# whether the norm of the gradient at the final point was within tolerance.\n",
    "# Position is the location of the minimum found. It is important to check\n",
    "# that converged is True before using the value of the position.\n",
    "\n",
    "print('L-BFGS Results')\n",
    "print('Converged:', results.converged)\n",
    "print('Location of the minimum:', results.position)\n",
    "print('Number of iterations:', results.num_iterations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using BFGS to solve the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation took: 0.031002 seconds\n",
      "BFGS Results\n",
      "Converged: True\n",
      "Location of the minimum: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Number of iterations: 10\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def quadratic_with_bfgs():\n",
    "  return tfp.optimizer.bfgs_minimize(\n",
    "    quadratic,\n",
    "    initial_position=tf.constant(start),\n",
    "    tolerance=tolerance)\n",
    "\n",
    "results = run(quadratic_with_bfgs)\n",
    "\n",
    "print('BFGS Results')\n",
    "print('Converged:', results.converged)\n",
    "print('Location of the minimum:', results.position)\n",
    "print('Number of iterations:', results.num_iterations)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support for Batch Processing\n",
    "Both BFGS and L-BFGS support the use of batch calculations to perform a variety of operations, such as optimizing a function from many different starting points, or optimizing multiple parameter functions from a single point.\n",
    "\n",
    "Single function, multiple starting points\n",
    "The Himmelblau function is the standard optimization test case. The expression for this function is as follows:\n",
    "$$f(x,y)=(x^2+y-11)^2+(x+y^2-7)^2$$\n",
    "\n",
    "This function includes four minimums:\n",
    "* (3,2)\n",
    "* (-2.805118, 3.131312)\n",
    "* (-3.779310, -3.283186)\n",
    "* (3.584428, -1.848126)\n",
    "\n",
    "All these minima can be reached from the corresponding starting points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation took: 0.060987 seconds\n",
      "Converged: [ True  True  True  True]\n",
      "Minima: [[ 3.          2.        ]\n",
      " [-2.80511809  3.13131252]\n",
      " [-3.77931025 -3.28318599]\n",
      " [ 3.58442834 -1.84812653]]\n"
     ]
    }
   ],
   "source": [
    "# The function to minimize must take as input a tensor of shape [..., n]. In\n",
    "# this n=2 is the size of the domain of the input and [...] are batching\n",
    "# dimensions. The return value must be of shape [...], i.e. a batch of scalars\n",
    "# with the objective value of the function evaluated at each input point.\n",
    "\n",
    "@make_val_and_grad_fn\n",
    "def himmelblau(coord):\n",
    "  x, y = coord[..., 0], coord[..., 1]\n",
    "  return (x * x + y - 11) ** 2 + (x + y * y - 7) ** 2\n",
    "\n",
    "starts = tf.constant([[1, 1],\n",
    "                      [-2, 2],\n",
    "                      [-1, -1],\n",
    "                      [1, -2]], dtype='float64')\n",
    "\n",
    "# The stopping_condition allows to further specify when should the search stop.\n",
    "# The default, tfp.optimizer.converged_all, will proceed until all points have\n",
    "# either converged or failed. There is also a tfp.optimizer.converged_any to\n",
    "# stop as soon as the first point converges, or all have failed.\n",
    "\n",
    "@tf.function\n",
    "def batch_multiple_starts():\n",
    "  return tfp.optimizer.lbfgs_minimize(\n",
    "      himmelblau, initial_position=starts,\n",
    "      stopping_condition=tfp.optimizer.converged_all,\n",
    "      tolerance=1e-8)\n",
    "\n",
    "results = run(batch_multiple_starts)\n",
    "print('Converged:', results.converged)\n",
    "print('Minima:', results.position)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple functions\n",
    "For demonstration purposes, we optimize a large number of randomly generated high-dimensional quadratic surfaces simultaneously in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation took: 1.476638 seconds\n",
      "All converged: True\n",
      "Largest error: 3.536350234867314e-08\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(12345)\n",
    "\n",
    "dim = 100\n",
    "batches = 500\n",
    "minimum = np.random.randn(batches, dim)\n",
    "scales = np.exp(np.random.randn(batches, dim))\n",
    "\n",
    "@make_val_and_grad_fn\n",
    "def quadratic(x):\n",
    "  return tf.reduce_sum(input_tensor=scales * (x - minimum)**2, axis=-1)\n",
    "\n",
    "# Make all starting points (1, 1, ..., 1). Note not all starting points need\n",
    "# to be the same.\n",
    "start = tf.ones((batches, dim), dtype='float64')\n",
    "\n",
    "@tf.function\n",
    "def batch_multiple_functions():\n",
    "  return tfp.optimizer.lbfgs_minimize(\n",
    "      quadratic, initial_position=start,\n",
    "      stopping_condition=tfp.optimizer.converged_all,\n",
    "      max_iterations=100,\n",
    "      tolerance=1e-8)\n",
    "\n",
    "results = run(batch_multiple_functions)\n",
    "print('All converged:', np.all(results.converged))\n",
    "print('Largest error:', np.max(results.position - minimum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged: [ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True]\n",
      "Minima: [[-0.20470766  0.47894334 -0.51943872 ... -0.74853155  0.58496974\n",
      "   0.15267657]\n",
      " [-1.56565729 -0.56254019 -0.03266414 ... -1.41341604  1.29660784\n",
      "   0.25227521]\n",
      " [ 1.1274811  -0.56836345  0.30936217 ...  1.35029974 -0.38665332\n",
      "   0.86598954]\n",
      " ...\n",
      " [ 2.47402656  2.00147886 -0.41025188 ... -0.34058461 -0.25413308\n",
      "   0.63119933]\n",
      " [-0.12418664 -0.84148144 -0.3013198  ...  1.11847358 -0.68176484\n",
      "   0.51423071]\n",
      " [-1.13034075 -0.02594974 -0.33531663 ... -1.98849254 -2.14429131\n",
      "  -0.34186901]]\n"
     ]
    }
   ],
   "source": [
    "print('Converged:', results.converged)\n",
    "print('Minima:', results.position)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
